#!/usr/bin/env python3
"""
å¯¼å‡ºæ•°æ®åº“ä¸ºJSONæ–‡ä»¶çš„è„šæœ¬
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

from db.session import SessionLocal
from sqlalchemy import text


def export_table(db, table_name: str, schema: str = "ai") -> dict:
    """å¯¼å‡ºå•ä¸ªè¡¨çš„æ•°æ®"""
    
    try:
        # æ£€æŸ¥è¡¨æ˜¯å¦æœ‰idåˆ—
        check_id_result = db.execute(text(f"""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_schema = '{schema}' 
            AND table_name = '{table_name}' 
            AND column_name = 'id'
        """))
        
        has_id = check_id_result.fetchone() is not None
        
        # æ ¹æ®æ˜¯å¦æœ‰idåˆ—æ¥æ„å»ºæŸ¥è¯¢
        if has_id:
            result = db.execute(text(f"SELECT * FROM {schema}.{table_name} ORDER BY id"))
        else:
            result = db.execute(text(f"SELECT * FROM {schema}.{table_name}"))
        
        rows = result.fetchall()
        
        # è·å–åˆ—å
        columns = result.keys()
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for row in rows:
            row_dict = {}
            for i, column in enumerate(columns):
                value = row[i]
                # å¤„ç†ç‰¹æ®Šç±»å‹
                if isinstance(value, datetime):
                    row_dict[column] = value.isoformat()
                else:
                    row_dict[column] = value
            data.append(row_dict)
        
        return {
            "count": len(data),
            "data": data
        }
        
    except Exception as e:
        print(f"âš ï¸  å¯¼å‡ºè¡¨ {table_name} å¤±è´¥: {e}")
        return {
            "count": 0,
            "data": [],
            "error": str(e)
        }


def export_database():
    """å¯¼å‡ºæ•´ä¸ªæ•°æ®åº“"""
    
    db = SessionLocal()
    try:
        # å®šä¹‰è¦å¯¼å‡ºçš„è¡¨
        tables_to_export = [
            "knowledge",
            "learning_resource", 
            "knowledge_resource_association",
            "knowledge_prerequisites",
            "video_segments",
            "user_profile",
            "user_learning_path",
            "user_learning_progress"
        ]
        
        print("ğŸš€ å¼€å§‹å¯¼å‡ºæ•°æ®åº“...")
        
        export_data = {
            "export_timestamp": datetime.now().isoformat(),
            "database_name": "ai",
            "schema": "ai",
            "tables": {}
        }
        
        # å¯¼å‡ºæ¯ä¸ªè¡¨
        for table in tables_to_export:
            print(f"ğŸ“Š å¯¼å‡ºè¡¨: {table}")
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            check_result = db.execute(text(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'ai' 
                    AND table_name = '{table}'
                );
            """))
            
            table_exists = check_result.scalar()
            
            if table_exists:
                export_data["tables"][table] = export_table(db, table)
                count = export_data["tables"][table]["count"]
                print(f"  âœ… æˆåŠŸå¯¼å‡º {count} æ¡è®°å½•")
            else:
                print(f"  â­ï¸  è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                export_data["tables"][table] = {
                    "count": 0,
                    "data": [],
                    "note": "table_not_exists"
                }
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        total_records = sum(
            table_data["count"] 
            for table_data in export_data["tables"].values()
        )
        
        export_data["summary"] = {
            "total_tables": len([t for t in export_data["tables"].values() if t["count"] > 0]),
            "total_records": total_records,
            "export_method": "python_sqlalchemy"
        }
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"kairos_database_export_{timestamp}.json"
        
        # å†™å…¥æ–‡ä»¶
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æ•°æ®åº“å¯¼å‡ºå®Œæˆ!")
        print(f"ğŸ“„ æ–‡ä»¶å: {filename}")
        print(f"ğŸ“Š æ€»è®¡: {len(export_data['tables'])} ä¸ªè¡¨, {total_records} æ¡è®°å½•")
        
        # æ˜¾ç¤ºå„è¡¨ç»Ÿè®¡
        print(f"\nğŸ“‹ å„è¡¨è®°å½•æ•°:")
        for table, data in export_data["tables"].items():
            if data["count"] > 0:
                print(f"  {table}: {data['count']} æ¡")
        
        return filename
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return None
    finally:
        db.close()


def main():
    """ä¸»å‡½æ•°"""
    print("æ•°æ®åº“å¯¼å‡ºå·¥å…·")
    print("================")
    
    # æ ‡å‡†å¯¼å‡º
    standard_file = export_database()
    
    print(f"\nğŸ‰ å¯¼å‡ºå®Œæˆ!")
    if standard_file:
        print(f"ğŸ“„ å¯¼å‡ºæ–‡ä»¶: {standard_file}")


if __name__ == "__main__":
    main()