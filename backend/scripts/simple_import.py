#!/usr/bin/env python3
"""
ç®€å•æ‰¹é‡å¯¼å…¥å­¦ä¹ èµ„æºåˆ°æ•°æ®åº“çš„è„šæœ¬ï¼ˆä¸è¿›è¡ŒVTTåˆ†æï¼‰
"""

import os
import sys
import re
from pathlib import Path
from typing import List, Dict
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env'))

from db.session import SessionLocal
from db.models import Knowledge, LearningResource


class SimpleResourceImporter:
    """ç®€å•èµ„æºå¯¼å…¥å™¨ï¼ˆåªå¯¼å…¥åŸºç¡€ä¿¡æ¯ï¼Œä¸è¿›è¡ŒAIåˆ†æï¼‰"""
    
    def __init__(self):
        self.db = SessionLocal()
        self.imported_count = 0
        self.skipped_count = 0
        self.error_count = 0
        self.domains = {
            "ç”Ÿæˆå¼AI": ["ç”Ÿæˆå¼AI", "GenAI", "Generative AI", "GPT", "LLM", "èªè¨€æ¨¡å‹", "Transformer", "ChatGPT"],
            "æ©Ÿå™¨å­¸ç¿’": ["æ©Ÿå™¨å­¸ç¿’", "Machine Learning", "ML", "æ¨¡å‹", "æ·±åº¦å­¸ç¿’", "ç¥ç¶“ç¶²è·¯", "å¯è§£é‡‹", "Explainable"],
            "æ·±åº¦å¼·åŒ–å­¸ç¿’": ["å¼ºåŒ–å­¸ç¿’", "Reinforcement Learning", "RL", "DRL", "Policy", "Q-learning", "PPO", "Actor", "Critic"],
            "è¨ˆç®—æ©Ÿè¦–è¦º": ["Computer Vision", "CV", "Image", "Vision", "åœ–åƒ", "è¦–è¦º", "CNN", "Diffusion"],
            "è‡ªç„¶èªè¨€è™•ç†": ["NLP", "Natural Language", "èªè¨€è™•ç†", "æ–‡æœ¬", "Text"],
            "AIå€«ç†èˆ‡å®‰å…¨": ["AIå€«ç†", "AIå®‰å…¨", "åè¦‹", "å®‰å…¨æ€§", "Ethics", "Safety", "Bias", "å€«ç†"]
        }
    
    def detect_domain(self, title: str, description: str = "") -> str:
        """æ ¹æ“šæ¨™é¡Œå’Œæè¿°æª¢æ¸¬å­¸ç§‘é ˜åŸŸ"""
        text = f"{title} {description}".lower()
        
        # è¨ˆç®—æ¯å€‹é ˜åŸŸçš„åŒ¹é…åˆ†æ•¸
        domain_scores = {}
        for domain, keywords in self.domains.items():
            score = 0
            for keyword in keywords:
                if keyword.lower() in text:
                    score += 1
            domain_scores[domain] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„é ˜åŸŸ
        best_domain = max(domain_scores, key=domain_scores.get)
        if domain_scores[best_domain] > 0:
            return best_domain
        else:
            return "é€šç”¨AI"  # é»˜èªé ˜åŸŸ
    
    def extract_title_from_filename(self, filename: str) -> str:
        """å¾æ–‡ä»¶åæå–æ¨™é¡Œ"""
        # ç§»é™¤æ–‡ä»¶æ“´å±•å
        title = Path(filename).stem
        
        # æ¸…ç†å¸¸è¦‹çš„æ¨¡å¼
        title = re.sub(r'\.zh-TW$', '', title)
        title = re.sub(r'\.en$', '', title)
        title = re.sub(r'_info$', '', title)
        
        # æ›¿æ›ä¸‹åŠƒç·šç‚ºç©ºæ ¼
        title = title.replace('_', ' ')
        
        return title.strip()
    
    def get_resource_type(self, filename: str) -> str:
        """æ ¹æ“šæ–‡ä»¶æ“´å±•åç¢ºå®šè³‡æºé¡å‹"""
        ext = Path(filename).suffix.lower()
        
        type_mapping = {
            '.mp4': 'video',
            '.webm': 'video', 
            '.avi': 'video',
            '.vtt': 'subtitle',
            '.srt': 'subtitle',
            '.pdf': 'document',
            '.pptx': 'presentation',
            '.ppt': 'presentation',
            '.txt': 'text',
            '.md': 'text',
            '.json': 'data',
            '.description': 'description'
        }
        
        return type_mapping.get(ext, 'unknown')
    
    def read_description_file(self, desc_path: Path) -> str:
        """è®€å–æè¿°æ–‡ä»¶å…§å®¹"""
        try:
            with open(desc_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è®€å–æè¿°æ–‡ä»¶ {desc_path}: {e}")
            return ""
    
    def scan_directory(self, directory: Path) -> List[Dict]:
        """æƒæç›®éŒ„ä¸­çš„å­¸ç¿’è³‡æº"""
        resources = []
        
        # ç²å–æ‰€æœ‰æ–‡ä»¶
        all_files = list(directory.glob('*'))
        
        # æŒ‰ç…§ä¸»æ–‡ä»¶åˆ†çµ„ (åŸºæ–¼æ–‡ä»¶åå‰ç¶´)
        file_groups = {}
        
        for file_path in all_files:
            if file_path.is_file():
                # æå–åŸºç¤æ–‡ä»¶å (ä¸å«æ“´å±•åå’Œèªè¨€æ¨™è­˜)
                base_name = file_path.stem
                base_name = re.sub(r'\.zh-TW$', '', base_name)
                base_name = re.sub(r'\.en$', '', base_name)
                base_name = re.sub(r'_info$', '', base_name)
                
                if base_name not in file_groups:
                    file_groups[base_name] = []
                file_groups[base_name].append(file_path)
        
        # è™•ç†æ¯å€‹æ–‡ä»¶çµ„
        for base_name, files in file_groups.items():
            # æ‰¾ä¸»è¦è³‡æºæ–‡ä»¶ (è¦–é »æˆ–æ–‡æª”)
            main_file = None
            description_file = None
            subtitle_files = []
            
            for file_path in files:
                resource_type = self.get_resource_type(file_path.name)
                
                if resource_type in ['video', 'document', 'presentation']:
                    if main_file is None:  # å–ç¬¬ä¸€å€‹ä¸»è¦æ–‡ä»¶
                        main_file = file_path
                elif resource_type == 'description':
                    description_file = file_path
                elif resource_type == 'subtitle':
                    subtitle_files.append(file_path)
            
            # å¦‚æœæ‰¾åˆ°ä¸»è¦æ–‡ä»¶ï¼Œå‰µå»ºè³‡æºè¨˜éŒ„
            if main_file:
                title = self.extract_title_from_filename(base_name)
                description = ""
                
                if description_file:
                    description = self.read_description_file(description_file)
                
                domain = self.detect_domain(title, description)
                
                resource = {
                    'title': title,
                    'resource_type': self.get_resource_type(main_file.name),
                    'resource_url': str(main_file.absolute()),
                    'description': description,
                    'domain': domain,
                    'subtitle_files': [str(f.absolute()) for f in subtitle_files],
                    'base_directory': str(directory.absolute())
                }
                
                resources.append(resource)
        
        return resources
    
    def import_basic_resource(self, resource: Dict) -> bool:
        """å°å…¥åŸºç¤è³‡æºä¿¡æ¯åˆ°æ•¸æ“šåº«"""
        try:
            # æª¢æŸ¥è³‡æºæ˜¯å¦å·²å­˜åœ¨
            existing = self.db.query(LearningResource).filter(
                LearningResource.resource_url == resource['resource_url']
            ).first()
            
            if existing:
                print(f"  â­ï¸  è³‡æºå·²å­˜åœ¨ï¼Œè·³é: {resource['title']}")
                self.skipped_count += 1
                return True
            
            # å‰µå»ºæ–°çš„å­¸ç¿’è³‡æº
            new_resource = LearningResource(
                title=resource['title'],
                resource_type=resource['resource_type'],
                resource_url=resource['resource_url'],
                description=resource['description'],
                language='zh',
                quality_score=5,  # é»˜èªè³ªé‡åˆ†æ•¸
                is_available=True
            )
            
            self.db.add(new_resource)
            self.db.commit()
            self.db.refresh(new_resource)
            
            print(f"  âœ… å°å…¥æˆåŠŸ: {resource['title']}")
            self.imported_count += 1
            return True
            
        except Exception as e:
            print(f"  âŒ å°å…¥å¤±æ•—: {resource['title']} - {e}")
            self.error_count += 1
            self.db.rollback()
            return False
    
    def process_directory(self, directory: str):
        """è™•ç†å–®å€‹ç›®éŒ„"""
        directory_path = Path(directory)
        
        if not directory_path.exists():
            print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {directory}")
            return
        
        print(f"\nğŸ“ è™•ç†ç›®éŒ„: {directory_path.name}")
        
        # æƒæè³‡æº
        resources = self.scan_directory(directory_path)
        print(f"   ç™¼ç¾ {len(resources)} å€‹å­¸ç¿’è³‡æº")
        
        # è™•ç†æ¯å€‹è³‡æº
        for i, resource in enumerate(resources, 1):
            print(f"\nğŸ¯ è™•ç†è³‡æº {i}/{len(resources)}: {resource['title']}")
            print(f"   é¡å‹: {resource['resource_type']}, é ˜åŸŸ: {resource['domain']}")
            
            # å°å…¥åŸºç¤è³‡æºä¿¡æ¯
            self.import_basic_resource(resource)
    
    def run(self, directories: List[str]):
        """é‹è¡Œæ‰¹é‡å°å…¥"""
        print("ğŸš€ é–‹å§‹ç°¡å–®æ‰¹é‡å°å…¥å­¸ç¿’è³‡æºï¼ˆåƒ…åŸºç¤ä¿¡æ¯ï¼‰")
        print(f"ğŸ“Š å¾…è™•ç†ç›®éŒ„æ•¸é‡: {len(directories)}")
        
        start_time = datetime.now()
        
        # è™•ç†æ¯å€‹ç›®éŒ„
        for directory in directories:
            self.process_directory(directory)
        
        # é—œé–‰æ•¸æ“šåº«é€£æ¥
        self.db.close()
        
        # è¼¸å‡ºçµ±è¨ˆä¿¡æ¯
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\n" + "="*60)
        print(f"ğŸ“‹ ç°¡å–®æ‰¹é‡å°å…¥å®Œæˆ!")
        print(f"â±ï¸  ç”¨æ™‚: {duration}")
        print(f"âœ… æˆåŠŸå°å…¥: {self.imported_count} å€‹è³‡æº")
        print(f"â­ï¸  è·³éå·²å­˜åœ¨: {self.skipped_count} å€‹è³‡æº")
        print(f"âŒ å°å…¥å¤±æ•—: {self.error_count} å€‹è³‡æº")
        print(f"ğŸ“Š ç¸½è™•ç†: {self.imported_count + self.skipped_count + self.error_count} å€‹è³‡æº")
        print(f"\nğŸ’¡ æç¤º: ç¨å¾Œå¯ä»¥ä½¿ç”¨ transcript_analyzer API å°VTTæ–‡ä»¶é€²è¡Œåˆ†æ")


def main():
    """ä¸»å‡½æ•¸"""
    # è¦è™•ç†çš„ç›®éŒ„åˆ—è¡¨
    directories = [
        "data/firecrawlcrawl_results_20250725_222601",
        "data/firecrawlcrawl_results_20250725_035351", 
        "data/firecrawlcrawl_results_20250725_031705"
    ]
    
    # å‰µå»ºå°å…¥å™¨ä¸¦é‹è¡Œ
    importer = SimpleResourceImporter()
    importer.run(directories)


if __name__ == "__main__":
    main()